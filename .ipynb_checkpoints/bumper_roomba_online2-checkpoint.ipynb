{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/JuliaPOMDP`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaPOMDP/Registry`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h\u001b[32m\u001b[1m  Building\u001b[22m\u001b[39m LibCURL ─→ `~/.julia/packages/LibCURL/OoXMv/deps/build.log`\n",
      "\u001b[32m\u001b[1m  Building\u001b[22m\u001b[39m WinRPM ──→ `~/.julia/packages/WinRPM/Y9QdZ/deps/build.log`\n",
      "\u001b[32m\u001b[1m  Building\u001b[22m\u001b[39m Homebrew → `~/.julia/packages/Homebrew/l8kUw/deps/build.log`\n",
      "\u001b[32m\u001b[1m  Building\u001b[22m\u001b[39m Cairo ───→ `~/.julia/packages/Cairo/CXPG1/deps/build.log`\n"
     ]
    }
   ],
   "source": [
    "# activate project environment\n",
    "# include these lines of code in any future scripts/notebooks\n",
    "#---\n",
    "import Pkg\n",
    "if !haskey(Pkg.installed(), \"AA228FinalProject\")\n",
    "    jenv = joinpath(dirname(@__FILE__()), \".\") # this assumes the notebook is in the same dir\n",
    "    # as the Project.toml file, which should be in top level dir of the project. \n",
    "    # Change accordingly if this is not the case.\n",
    "    Pkg.activate(jenv)\n",
    "end\n",
    "Pkg.instantiate()\n",
    "Pkg.build(\"Cairo\")\n",
    "#---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "using AA228FinalProject\n",
    "using TabularTDLearning\n",
    "using POMDPs\n",
    "using MCTS\n",
    "using ARDESPOT\n",
    "using POMCPOW\n",
    "using POMDPModels\n",
    "using POMDPPolicies\n",
    "using BasicPOMCP\n",
    "using POMDPPolicies\n",
    "using BeliefUpdaters\n",
    "using ParticleFilters\n",
    "using POMDPSimulators\n",
    "using Cairo\n",
    "using Gtk\n",
    "using Random\n",
    "using Printf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor = Bumper()\n",
    "config = 3 # 1,2, or 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DiscreteRoombaStateSpace(50, 50, 50)\n",
    "v_steps = range(0.0, stop = 10.0, length = 10) \n",
    "om_steps = range(-1.0 * pi + 0.01, stop = 1.0 * pi, length = 200) \n",
    "\n",
    "# discrete states space, discrete action space\n",
    "m_mcts = RoombaPOMDP(sensor=sensor, mdp=RoombaMDP(sspace=ds, aspace=[RoombaAct(v,om) for v in v_steps for om in om_steps], config=config));\n",
    "\n",
    "# Cont states space, cont action space\n",
    "m_pomcpow = RoombaPOMDP(sensor=sensor, mdp=RoombaMDP(config=config));\n",
    "                                    \n",
    "# Cont states space, discrete action space\n",
    "m_pomcp = RoombaPOMDP(sensor=sensor, mdp=RoombaMDP(aspace=[RoombaAct(v,om) for v in v_steps for om in om_steps], config=config));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_particles = 2000\n",
    "resampler = BumperResampler(num_particles)\n",
    "\n",
    "spf_mcts = SimpleParticleFilter(m_mcts, resampler)\n",
    "spf_pomcpow = SimpleParticleFilter(m_pomcpow, resampler)\n",
    "spf_pomcp = SimpleParticleFilter(m_pomcp, resampler)\n",
    "spf_ardespot = SimpleParticleFilter(m_pomcp, resampler)\n",
    "\n",
    "\n",
    "v_noise_coefficient = 2.0\n",
    "om_noise_coefficient = 0.5\n",
    "\n",
    "belief_updater_mcts = RoombaParticleFilter(spf_mcts, v_noise_coefficient, om_noise_coefficient);\n",
    "belief_updater_pomcp = RoombaParticleFilter(spf_pomcp, v_noise_coefficient, om_noise_coefficient);\n",
    "belief_updater_pomcpow = RoombaParticleFilter(spf_pomcpow, v_noise_coefficient, om_noise_coefficient);\n",
    "belief_updater_ardespot = RoombaParticleFilter(spf_ardespot, v_noise_coefficient, om_noise_coefficient);\n",
    "\n",
    "\n",
    "# POMCP SOLVER\n",
    "pomcp_solver = POMCPSolver()\n",
    "pomcp_policy = solve(pomcp_solver, m_pomcp);\n",
    "\n",
    "# POMCPOW SOLVER\n",
    "pomcpow_solver = POMCPOWSolver(criterion=MaxUCB(20.0))\n",
    "pomcpow_policy = solve(pomcpow_solver, m_pomcpow);\n",
    "\n",
    "# MCTS SOLVER\n",
    "mcts_solver = MCTSSolver(n_iterations=50, depth=10, exploration_constant=5.0) # initializes the Solver type\n",
    "mcts_policy = solve(mcts_solver, m_mcts);\n",
    "\n",
    "# ARDESPOT SOLVER\n",
    "ardespot_solver = DESPOTSolver(bounds=(-20.0, 0.0))\n",
    "# ardespot_solver = DESPOTSolver(bounds=(DefaultPolicyLB(RandomSolver()), 0.0))\n",
    "ardespot_policy = solve(ardespot_solver, m_pomcp);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first seed the environment\n",
    "Random.seed!(5)\n",
    "\n",
    "# reset the policy\n",
    "# p = ToEnd(0) # here, the argument sets the time-steps elapsed to 0\n",
    "\n",
    "# run the simulation\n",
    "c = @GtkCanvas()\n",
    "win = GtkWindow(c, \"Roomba Environment\", 600, 600)\n",
    "m = m_pomcp\n",
    "policy = pomcp_policy\n",
    "belief_updater = belief_updater_ardespot\n",
    "for (t, step) in enumerate(stepthrough(m, policy, belief_updater, max_steps=100))\n",
    "    @guarded draw(c) do widget\n",
    "        \n",
    "        # the following lines render the room, the particles, and the roomba\n",
    "        ctx = getgc(c)\n",
    "        set_source_rgb(ctx,1,1,1)\n",
    "        paint(ctx)\n",
    "        render(ctx, m, step)\n",
    "        \n",
    "        # render some information that can help with debugging\n",
    "        # here, we render the time-step, the state, and the observation\n",
    "        move_to(ctx,300,400)\n",
    "        show_text(ctx, @sprintf(\"t=%d, state=%s, o=%.3f\",t,string(step.s),step.o))\n",
    "    end\n",
    "    show(c)\n",
    "    sleep(0.1) # to slow down the simulation\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1\n",
      "num steps: 21, traj rewards: -16.099999999999998\n",
      "2\n",
      "num steps: 3, traj rewards: -11.299999999999999\n",
      "3\n",
      "0.76973652073499780.39130927404692820.205611422772765920.13488974389586140.110268763126313240.063493888191826940.0605879931365484040.04333618926081850.032899747831031710.0170403940630648730.0311931525163103850.82302000203979380.40803734540862680.182186388407639650.057897151479101974-0.041787999662173884-0.05747278409391565-0.3994923468611023-0.12305224147441042-0.06229162764468643-0.03014089086795945-0.012381592633271155-0.009852351076312549-0.006997120197669376-0.002271391348320592-0.010647567028469127-0.009420845883282541-0.0017237529070491392-0.00185021574158997230.00243669128812697840.00337129497783725250.0069187295656674970.004492972125657406-0.004156917573207318-0.011279154390875366-0.015217103839293047-0.011603748756922432-0.012792027325058273-0.010286119867412208-0.0040578580054287175-0.00212742485501985630.0020786351478123063-0.003666078867523258-0.008460922885429014-0.013796583762012805-0.014854414027334478-0.021671609660441855-0.01891375066992923-0.005186205255136196-0.006641515908646273num steps: 100, traj rewards: -14.999999999999973\n",
      "4\n",
      "0.0443153274014388840.0298966170139108170.0170452748756701740.0105193068137582610.0057324569246616010.0051104066415200090.0063768463914472950.00207857223512288460.002111325998932256-0.0025495895010418450.001052931884156838-0.00191670903404126020.0009093182064801985-0.0033334872187123776-0.0005757213215536565-0.0027104391087022820.00096717619350798060.00114663403467144770.0021484467804223370.00034593214928435936-0.0005838902769209914-0.003335535212474327-0.0003924889113032914-0.0014260530910292918-0.00194830517668372930.00165857560169803150.002610828914786114-0.00014985211954110338-0.0012245923026280043-0.003653803890911342-0.0010491302870055848-0.004589249374461441-0.00252665522264465-0.00158073595463354560.00137633826100854763.471259693149306e-50.00097342213829148230.00140269616521646130.00150902986132762580.0003296388695166342-0.0010147592002605257-0.000352843865255097-0.0022981270137240606-0.004237739669264572-0.005173967796955767-0.0026979132634558280.00202213072088131430.00149679001275908940.002472442135838103-0.00013049157263632025num steps: 100, traj rewards: -14.999999999999973\n",
      "5\n",
      "-2.15759195411254-1.7246498897603795-1.288288847679503-0.8186341387270026-0.40095076404846464-0.18132665438462403-0.0620100414939387250.00149501603140599070.0285859782190923260.043873075119027580.041201084713098260.0353880242149581250.02105024004363730.00190437934521295320.003940901117377479-0.09581122775012632num steps: 66, traj rewards: -0.5999999999999854\n",
      " 27.188616 seconds (242.56 M allocations: 8.354 GiB, 8.95% gc time)\n",
      "Mean Total Reward: -11.600, StdErr Total Reward: 2.868"
     ]
    }
   ],
   "source": [
    "using Statistics\n",
    "\n",
    "function evaluate()\n",
    "    total_rewards = []\n",
    "\n",
    "    for exp = 1:5\n",
    "        println(string(exp))\n",
    "\n",
    "        Random.seed!(exp)\n",
    "\n",
    "        p = ToEnd(0)\n",
    "        \n",
    "        num_steps = 0\n",
    "        traj_rewards = 0\n",
    "        for (t, step) in enumerate(stepthrough(m, p, belief_updater, max_steps=100))\n",
    "\n",
    "            traj_rewards += step.r \n",
    "            num_steps = t\n",
    "        end\n",
    "        #traj_rewards = sum([step.r for step in stepthrough(m,p,belief_updater, max_steps=100)])\n",
    "\n",
    "        \n",
    "\n",
    "        push!(total_rewards, traj_rewards)\n",
    "    end\n",
    "end\n",
    "@printf(\" \")\n",
    "@time evaluate()\n",
    "@printf(\"Mean Total Reward: %.3f, StdErr Total Reward: %.3f\", mean(total_rewards), std(total_rewards)/sqrt(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.1",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
