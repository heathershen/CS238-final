{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/JuliaPOMDP`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaPOMDP/Registry`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h\u001b[32m\u001b[1m  Building\u001b[22m\u001b[39m LibCURL ─→ `~/.julia/packages/LibCURL/OoXMv/deps/build.log`\n",
      "\u001b[32m\u001b[1m  Building\u001b[22m\u001b[39m WinRPM ──→ `~/.julia/packages/WinRPM/Y9QdZ/deps/build.log`\n",
      "\u001b[32m\u001b[1m  Building\u001b[22m\u001b[39m Homebrew → `~/.julia/packages/Homebrew/l8kUw/deps/build.log`\n",
      "\u001b[32m\u001b[1m  Building\u001b[22m\u001b[39m Cairo ───→ `~/.julia/packages/Cairo/CXPG1/deps/build.log`\n"
     ]
    }
   ],
   "source": [
    "# activate project environment\n",
    "# include these lines of code in any future scripts/notebooks\n",
    "#---\n",
    "import Pkg\n",
    "if !haskey(Pkg.installed(), \"AA228FinalProject\")\n",
    "    jenv = joinpath(dirname(@__FILE__()), \".\") # this assumes the notebook is in the same dir\n",
    "    # as the Project.toml file, which should be in top level dir of the project. \n",
    "    # Change accordingly if this is not the case.\n",
    "    Pkg.activate(jenv)\n",
    "end\n",
    "Pkg.instantiate()\n",
    "Pkg.build(\"Cairo\")\n",
    "#---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "using AA228FinalProject\n",
    "using TabularTDLearning\n",
    "using POMDPs\n",
    "using MCTS\n",
    "using ARDESPOT\n",
    "using POMCPOW\n",
    "using POMDPModels\n",
    "using POMDPPolicies\n",
    "using BasicPOMCP\n",
    "using POMDPPolicies\n",
    "using BeliefUpdaters\n",
    "using ParticleFilters\n",
    "using POMDPSimulators\n",
    "using Cairo\n",
    "using Gtk\n",
    "using Random\n",
    "using Printf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor = Bumper()\n",
    "config = 2 # 1,2, or 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DiscreteRoombaStateSpace(50, 50, 50)\n",
    "v_steps = range(0.0, stop = 10.0, length = 10) \n",
    "om_steps = range(-1.0 * pi + 0.01, stop = 1.0 * pi, length = 200) \n",
    "\n",
    "# discrete states space, discrete action space\n",
    "m_mcts = RoombaPOMDP(sensor=sensor, mdp=RoombaMDP(sspace=ds, aspace=[RoombaAct(v,om) for v in v_steps for om in om_steps], config=config));\n",
    "\n",
    "# Cont states space, cont action space\n",
    "m_pomcpow = RoombaPOMDP(sensor=sensor, mdp=RoombaMDP(config=config));\n",
    "                                    \n",
    "# Cont states space, discrete action space\n",
    "m_pomcp = RoombaPOMDP(sensor=sensor, mdp=RoombaMDP(aspace=[RoombaAct(v,om) for v in v_steps for om in om_steps], config=config));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_particles = 5000\n",
    "resampler = BumperResampler(num_particles)\n",
    "\n",
    "spf_mcts = SimpleParticleFilter(m_mcts, resampler)\n",
    "spf_pomcpow = SimpleParticleFilter(m_pomcpow, resampler)\n",
    "spf_pomcp = SimpleParticleFilter(m_pomcp, resampler)\n",
    "spf_ardespot = SimpleParticleFilter(m_pomcp, resampler)\n",
    "\n",
    "\n",
    "v_noise_coefficient = 2.0\n",
    "om_noise_coefficient = 0.5\n",
    "\n",
    "belief_updater_mcts = RoombaParticleFilter(spf_mcts, v_noise_coefficient, om_noise_coefficient);\n",
    "belief_updater_pomcp = RoombaParticleFilter(spf_pomcp, v_noise_coefficient, om_noise_coefficient);\n",
    "belief_updater_pomcpow = RoombaParticleFilter(spf_pomcpow, v_noise_coefficient, om_noise_coefficient);\n",
    "belief_updater_ardespot = RoombaParticleFilter(spf_ardespot, v_noise_coefficient, om_noise_coefficient);\n",
    "\n",
    "\n",
    "# POMCP SOLVER\n",
    "pomcp_solver = POMCPSolver()\n",
    "pomcp_policy = solve(pomcp_solver, m_pomcp);\n",
    "\n",
    "# POMCPOW SOLVER\n",
    "pomcpow_solver = POMCPOWSolver(criterion=MaxUCB(20.0))\n",
    "pomcpow_policy = solve(pomcpow_solver, m_pomcpow);\n",
    "\n",
    "# MCTS SOLVER\n",
    "mcts_solver = MCTSSolver(n_iterations=50, depth=10, exploration_constant=5.0) # initializes the Solver type\n",
    "mcts_policy = solve(mcts_solver, m_mcts);\n",
    "\n",
    "# ARDESPOT SOLVER\n",
    "ardespot_solver = DESPOTSolver(bounds=(-20.0, 0.0))\n",
    "# ardespot_solver = DESPOTSolver(bounds=(DefaultPolicyLB(RandomSolver()), 0.0))\n",
    "ardespot_policy = solve(ardespot_solver, m_pomcp);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ErrorException",
     "evalue": "If all states are terminal, lower and upper bounds should be zero (L_0=-20       , U_0=0         ). (try IndependentBounds(l, u, check_terminal=true))",
     "output_type": "error",
     "traceback": [
      "If all states are terminal, lower and upper bounds should be zero (L_0=-20       , U_0=0         ). (try IndependentBounds(l, u, check_terminal=true))",
      "",
      "Stacktrace:",
      " [1] error(::String) at ./error.jl:33",
      " [2] macro expansion at ./printf.jl:171 [inlined]",
      " [3] bounds_sanity_check(::RoombaPOMDP{Bumper,Bool}, ::ScenarioBelief{RoombaState,Bool,MemorizingSource{MersenneTwister}}, ::Float64, ::Float64) at /Users/heathershen/.julia/packages/ARDESPOT/Xjyi4/src/bounds.jl:12",
      " [4] expand!(::ARDESPOT.DESPOT{RoombaState,RoombaAct,Bool}, ::Int64, ::DESPOTPlanner{RoombaPOMDP{Bumper,Bool},Tuple{Float64,Float64},MemorizingSource{MersenneTwister},MersenneTwister}) at /Users/heathershen/.julia/packages/ARDESPOT/Xjyi4/src/tree.jl:103",
      " [5] explore!(::ARDESPOT.DESPOT{RoombaState,RoombaAct,Bool}, ::Int64, ::DESPOTPlanner{RoombaPOMDP{Bumper,Bool},Tuple{Float64,Float64},MemorizingSource{MersenneTwister},MersenneTwister}) at /Users/heathershen/.julia/packages/ARDESPOT/Xjyi4/src/planner.jl:24",
      " [6] build_despot(::DESPOTPlanner{RoombaPOMDP{Bumper,Bool},Tuple{Float64,Float64},MemorizingSource{MersenneTwister},MersenneTwister}, ::ParticleCollection{RoombaState}) at /Users/heathershen/.julia/packages/ARDESPOT/Xjyi4/src/planner.jl:10",
      " [7] action(::DESPOTPlanner{RoombaPOMDP{Bumper,Bool},Tuple{Float64,Float64},MemorizingSource{MersenneTwister},MersenneTwister}, ::ParticleCollection{RoombaState}) at /Users/heathershen/.julia/packages/ARDESPOT/Xjyi4/src/pomdps_glue.jl:7",
      " [8] action_info at /Users/heathershen/.julia/packages/POMDPModelTools/eHEjm/src/info.jl:30 [inlined]",
      " [9] iterate(::POMDPSimulators.POMDPSimIterator{(:s, :a, :r, :sp, :t, :i, :ai, :b, :o, :bp, :ui),RoombaPOMDP{Bumper,Bool},DESPOTPlanner{RoombaPOMDP{Bumper,Bool},Tuple{Float64,Float64},MemorizingSource{MersenneTwister},MersenneTwister},RoombaParticleFilter,MersenneTwister,ParticleCollection{RoombaState},RoombaState}, ::Tuple{Int64,RoombaState,ParticleCollection{RoombaState}}) at /Users/heathershen/.julia/packages/POMDPSimulators/xyfJM/src/stepthrough.jl:102",
      " [10] iterate(::Base.Iterators.Enumerate{POMDPSimulators.POMDPSimIterator{(:s, :a, :r, :sp, :t, :i, :ai, :b, :o, :bp, :ui),RoombaPOMDP{Bumper,Bool},DESPOTPlanner{RoombaPOMDP{Bumper,Bool},Tuple{Float64,Float64},MemorizingSource{MersenneTwister},MersenneTwister},RoombaParticleFilter,MersenneTwister,ParticleCollection{RoombaState},RoombaState}}, ::Tuple{Int64,Tuple{Int64,RoombaState,ParticleCollection{RoombaState}}}) at ./iterators.jl:139",
      " [11] top-level scope at In[7]:28"
     ]
    }
   ],
   "source": [
    "# first seed the environment\n",
    "Random.seed!(5)\n",
    "\n",
    "# reset the policy\n",
    "# p = ToEnd(0) # here, the argument sets the time-steps elapsed to 0\n",
    "\n",
    "# run the simulation\n",
    "c = @GtkCanvas()\n",
    "win = GtkWindow(c, \"Roomba Environment\", 600, 600)\n",
    "m = m_pomcp\n",
    "policy = ardespot_policy\n",
    "belief_updater = belief_updater_ardespot\n",
    "for (t, step) in enumerate(stepthrough(m, policy, belief_updater, max_steps=100))\n",
    "    @guarded draw(c) do widget\n",
    "        \n",
    "        # the following lines render the room, the particles, and the roomba\n",
    "        ctx = getgc(c)\n",
    "        set_source_rgb(ctx,1,1,1)\n",
    "        paint(ctx)\n",
    "        render(ctx, m, step)\n",
    "        \n",
    "        # render some information that can help with debugging\n",
    "        # here, we render the time-step, the state, and the observation\n",
    "        move_to(ctx,300,400)\n",
    "        show_text(ctx, @sprintf(\"t=%d, state=%s, o=%.3f\",t,string(step.s),step.o))\n",
    "    end\n",
    "    show(c)\n",
    "    sleep(0.1) # to slow down the simulation\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "using Statistics\n",
    "\n",
    "v_discrete_mean = []\n",
    "v_discrete_std = []\n",
    "num_exp = 10\n",
    "for l = 10:10:100\n",
    "    total_rewards = []\n",
    "    v_steps = range(0.0, stop = 10.0, length = l) \n",
    "    om_steps = range(-1.0 * pi + 0.01, stop = 1.0 * pi, length = 100) \n",
    "    for exp = 1:num_exp\n",
    "        println(string(exp))\n",
    "\n",
    "        Random.seed!(exp)\n",
    "\n",
    "        # Cont states space, discrete action space\n",
    "        m_pomcp = RoombaPOMDP(sensor=sensor, mdp=RoombaMDP(aspace=[RoombaAct(v,om) for v in v_steps for om in om_steps], config=config));\n",
    "        pomcp_solver = POMCPSolver()\n",
    "        pomcp_policy = solve(pomcp_solver, m_pomcp);\n",
    "                            \n",
    "        m = m_pomcp\n",
    "        p = pomcp_policy\n",
    "        belief_updater = belief_updater_pomcp\n",
    "        traj_rewards = sum([step.r for step in stepthrough(m,p,belief_updater, max_steps=100)])\n",
    "        push!(total_rewards, traj_rewards)\n",
    "    end\n",
    "\n",
    "    push!(v_discrete_mean, mean(total_rewards))\n",
    "    push!(v_discrete_std, std(total_rewards)/sqrt(num_exp))                        \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "plot(10:10:100, v_discrete_mean, yerror = v_discrete_std, xlabel=\"Discretized Velocity Steps\", ylabel=\"Reward\")\n",
    "\n",
    "savefig(\"discrete_v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Any,1}:\n",
       "  -5.379999999999999 \n",
       "  -3.4200000000000004\n",
       "   1.5000000000000007\n",
       "  -6.319999999999999 \n",
       "  -2.6599999999999993\n",
       " -10.040000000000001 \n",
       "  -9.1               \n",
       "   1.7599999999999998\n",
       "  -1.8               \n",
       "  -2.8799999999999986"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_discrete_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "num steps: 11, traj rewards: -14.100000000000001\n",
      "2\n",
      "num steps: 2, traj rewards: -11.2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "using Statistics\n",
    "\n",
    "\n",
    "total_steps = []\n",
    "total_rewards = []\n",
    "num_exp = 10\n",
    "for exp = 1:num_exp\n",
    "    println(string(exp))\n",
    "\n",
    "    Random.seed!(exp)\n",
    "\n",
    "    \n",
    "    # Cont states space, discrete action space\n",
    "    m_pomcp = RoombaPOMDP(sensor=sensor, mdp=RoombaMDP(aspace=[RoombaAct(v,om) for v in v_steps for om in om_steps], config=config));\n",
    "    pomcp_solver = POMCPSolver()\n",
    "    pomcp_policy = solve(pomcp_solver, m_pomcp);\n",
    "\n",
    "    m = m_pomcp\n",
    "    p = pomcp_policy\n",
    "    belief_updater = belief_updater_pomcp\n",
    "                        \n",
    "    num_steps = 0\n",
    "    traj_rewards = 0\n",
    "    for (t, step) in enumerate(stepthrough(m, p, belief_updater, max_steps=100))\n",
    "        traj_rewards += step.r \n",
    "        num_steps = t\n",
    "    end        \n",
    "    println(\"num steps: \", string(num_steps), \", traj rewards: \",  string(traj_rewards))\n",
    "    push!(total_steps, num_steps)\n",
    "    push!(total_rewards, traj_rewards)\n",
    "end\n",
    "\n",
    "\n",
    "@printf(\" \")\n",
    "@printf(\"Mean Total Reward: %.3f, StdErr Total Reward: %.3f\", mean(total_rewards), std(total_rewards)/sqrt(num_exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.2"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ave_steps = sum(total_steps) / num_exp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.1",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
