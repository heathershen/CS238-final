{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/JuliaPOMDP`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaPOMDP/Registry`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h\u001b[32m\u001b[1m  Building\u001b[22m\u001b[39m LibCURL ─→ `~/.julia/packages/LibCURL/OoXMv/deps/build.log`\n",
      "\u001b[32m\u001b[1m  Building\u001b[22m\u001b[39m WinRPM ──→ `~/.julia/packages/WinRPM/Y9QdZ/deps/build.log`\n",
      "\u001b[32m\u001b[1m  Building\u001b[22m\u001b[39m Homebrew → `~/.julia/packages/Homebrew/l8kUw/deps/build.log`\n",
      "\u001b[32m\u001b[1m  Building\u001b[22m\u001b[39m Cairo ───→ `~/.julia/packages/Cairo/CXPG1/deps/build.log`\n"
     ]
    }
   ],
   "source": [
    "# activate project environment\n",
    "# include these lines of code in any future scripts/notebooks\n",
    "#---\n",
    "import Pkg\n",
    "if !haskey(Pkg.installed(), \"AA228FinalProject\")\n",
    "    jenv = joinpath(dirname(@__FILE__()), \".\") # this assumes the notebook is in the same dir\n",
    "    # as the Project.toml file, which should be in top level dir of the project. \n",
    "    # Change accordingly if this is not the case.\n",
    "    Pkg.activate(jenv)\n",
    "end\n",
    "Pkg.instantiate()\n",
    "Pkg.build(\"Cairo\")\n",
    "#---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Recompiling stale cache file /Users/sarahradz/.julia/compiled/v1.0/POMDPModels/GHWgR.ji for POMDPModels [355abbd5-f08e-5560-ac9e-8b5f2592a0ca]\n",
      "└ @ Base loading.jl:1190\n",
      "WARNING: Method definition GridWorld(Any...) in module POMDPModels at deprecated.jl:29 overwritten at deprecated.jl:53.\n",
      "┌ Info: Precompiling BasicPOMCP [d721219e-3fc6-5570-a8ef-e5402f47c49e]\n",
      "└ @ Base loading.jl:1192\n",
      "┌ Warning: Module POMDPSimulators with build ID 583949510576451 is missing from the cache.\n",
      "│ This may mean POMDPSimulators [e0d0a172-29c6-5d4e-96d0-f262df5d01fd] does not support precompilation but is imported by a module that does.\n",
      "└ @ Base loading.jl:947\n",
      "┌ Info: Precompiling CPUTime [a9c8d775-2e2e-55fc-8582-045d282d599e]\n",
      "└ @ Base loading.jl:1192\n",
      "┌ Warning: Module Compat with build ID 183112212295429 is missing from the cache.\n",
      "│ This may mean Compat [34da2185-b29b-5c13-b0c7-acf172513d20] does not support precompilation but is imported by a module that does.\n",
      "└ @ Base loading.jl:947\n",
      "┌ Info: Precompiling MCTS [e12ccd36-dcad-5f33-8774-9175229e7b33]\n",
      "└ @ Base loading.jl:1192\n",
      "┌ Warning: Module POMDPSimulators with build ID 583949510576451 is missing from the cache.\n",
      "│ This may mean POMDPSimulators [e0d0a172-29c6-5d4e-96d0-f262df5d01fd] does not support precompilation but is imported by a module that does.\n",
      "└ @ Base loading.jl:947\n",
      "┌ Info: Precompiling D3Trees [e3df1716-f71e-5df9-9e2d-98e193103c45]\n",
      "└ @ Base loading.jl:1192\n",
      "┌ Warning: Module JSON with build ID 145712129883242 is missing from the cache.\n",
      "│ This may mean JSON [682c06a0-de6a-54ab-a142-c8b1cf79cde6] does not support precompilation but is imported by a module that does.\n",
      "└ @ Base loading.jl:947\n",
      "┌ Info: Precompiling AbstractTrees [1520ce14-60c1-5f80-bbc7-55ef81b5835c]\n",
      "└ @ Base loading.jl:1192\n"
     ]
    }
   ],
   "source": [
    "# import necessary packages\n",
    "using AA228FinalProject\n",
    "using TabularTDLearning\n",
    "using POMDPs\n",
    "using POMDPModels\n",
    "using POMDPPolicies\n",
    "using BasicPOMCP\n",
    "using POMDPPolicies\n",
    "using BeliefUpdaters\n",
    "using ParticleFilters\n",
    "using POMDPSimulators\n",
    "using Cairo\n",
    "using Gtk\n",
    "using Random\n",
    "using Printf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor = Bumper()\n",
    "config = 3 # 1,2, or 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RoombaPOMDP{Bumper,Bool}(Bumper(), RoombaMDP{DataType,Array{RoombaAct,1}}\n",
       "  v_max: Float64 10.0\n",
       "  om_max: Float64 1.0\n",
       "  dt: Float64 0.5\n",
       "  contact_pen: Float64 -1.0\n",
       "  time_pen: Float64 -0.1\n",
       "  goal_reward: Float64 10.0\n",
       "  stairs_penalty: Float64 -10.0\n",
       "  config: Int64 3\n",
       "  room: AA228FinalProject.Room\n",
       "  sspace: ContinuousRoombaStateSpace <: Any\n",
       "  aspace: Array{RoombaAct}((100,))\n",
       "  _amap: Dict{RoombaAct,Int64}\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ContinuousRoombaStateSpace#DiscreteRoombaStateSpace(50, 50, 50)\n",
    "v_steps = range(0.0, stop = 10.0, length = 10) \n",
    "om_steps = range(0.0, stop = 1.0, length = 10) \n",
    "as = AA228FinalProject.gen_amap([RoombaAct(v,om) for v in v_steps for om in om_steps])\n",
    "\n",
    "m = RoombaPOMDP(sensor=sensor, mdp=RoombaMDP(sspace=ds, aspace=[RoombaAct(v,om) for v in v_steps for om in om_steps], config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_particles = 2000\n",
    "resampler = BumperResampler(num_particles)\n",
    "\n",
    "spf = SimpleParticleFilter(m, resampler)\n",
    "\n",
    "v_noise_coefficient = 2.0\n",
    "om_noise_coefficient = 0.5\n",
    "\n",
    "belief_updater = RoombaParticleFilter(spf, v_noise_coefficient, om_noise_coefficient);\n",
    "solver = POMCPSolver()\n",
    "planner = solve(solver, m);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the policy to test\n",
    "mutable struct ToEnd <: Policy\n",
    "    ts::Int64 # to track the current time-step.\n",
    "end\n",
    "\n",
    "# extract goal for heuristic controller\n",
    "goal_xy = get_goal_xy(m)\n",
    "\n",
    "\n",
    "# define a new function that takes in the policy struct and current belief,\n",
    "# and returns the desired action\n",
    "function POMDPs.action(p::ToEnd, b::ParticleCollection{RoombaState})\n",
    "\n",
    "    # for 50 steps, act randomly and quickly to learn surrounding info\n",
    "    if p.ts < 50\n",
    "        p.ts += 1\n",
    "        return RoombaAct(5, rand()) \n",
    "    end\n",
    "    p.ts += 1\n",
    "    \n",
    "    # after 50 steps of random learning, we follow a proportional controller \n",
    "    # to navigate directly to the goal, using the mean belief state\n",
    "    \n",
    "    # compute mean belief of a subset of particles\n",
    "    s = mean(b)\n",
    "    goal_x, goal_y = goal_xy\n",
    "    x,y,th = s[1:3]\n",
    "    ang_to_goal = atan(goal_y - y, goal_x - x)\n",
    "    del_angle = wrap_to_pi(ang_to_goal - th)\n",
    "    \n",
    "    # apply proportional control to compute the turn-rate\n",
    "    Kprop = 1.0\n",
    "    om = Kprop * del_angle\n",
    "    \n",
    "    # always travel at some fixed velocity\n",
    "    v = 5.0\n",
    "    \n",
    "    return RoombaAct(v, om)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first seed the environment\n",
    "Random.seed!(5)\n",
    "\n",
    "# reset the policy\n",
    "p = ToEnd(0) # here, the argument sets the time-steps elapsed to 0\n",
    "\n",
    "# run the simulation\n",
    "c = @GtkCanvas()\n",
    "win = GtkWindow(c, \"Roomba Environment\", 600, 600)\n",
    "for (t, step) in enumerate(stepthrough(m, p, belief_updater, max_steps=100))\n",
    "    @guarded draw(c) do widget\n",
    "        \n",
    "        # the following lines render the room, the particles, and the roomba\n",
    "        ctx = getgc(c)\n",
    "        set_source_rgb(ctx,1,1,1)\n",
    "        paint(ctx)\n",
    "        render(ctx, m, step)\n",
    "        \n",
    "        # render some information that can help with debugging\n",
    "        # here, we render the time-step, the state, and the observation\n",
    "        move_to(ctx,300,400)\n",
    "        show_text(ctx, @sprintf(\"t=%d, state=%s, o=%.3f\",t,string(step.s),step.o))\n",
    "    end\n",
    "    show(c)\n",
    "    sleep(0.1) # to slow down the simulation\n",
    "end\n",
    "\n",
    "#solver = QLearningSolver(m, learning_rate=0.1, n_episodes=5000, max_episode_length=50, eval_every=50, n_eval_traj=100)\n",
    "#solver = FIBSolver()\n",
    "solver = QMDPSolver(max_iterations=20, tolerance=1e-3) \n",
    "#fib_policy = solve(solver, m)\n",
    "#rand_policy = RandomPolicy(m);\n",
    "policy = solve(solver, m) # compute a pomdp policy\n",
    "\n",
    "#policy = create_policy(solver, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.1",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
